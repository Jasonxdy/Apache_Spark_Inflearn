{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark import SparkConf, SparkContext"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conf = SparkConf().setMaster(\"local\").setAppName(\"MinTemperatures\")\n", "sc = SparkContext(conf = conf)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def parseLine(line):\n", "    fields = line.split(',')\n", "    stationID = fields[0]\n", "    entryType = fields[2]\n", "    temperature = float(fields[3]) * 0.1 * (9.0 / 5.0) + 32.0\n", "    return (stationID, entryType, temperature)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lines = sc.textFile(\"file:///SparkCourse/1800.csv\")\n", "parsedLines = lines.map(parseLine)\n", "minTemps = parsedLines.filter(lambda x: \"TMIN\" in x[1])\n", "stationTemps = minTemps.map(lambda x: (x[0], x[2]))\n", "minTemps = stationTemps.reduceByKey(lambda x, y: min(x,y))\n", "results = minTemps.collect();"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for result in results:\n", "    print(result[0] + \"\\t{:.2f}F\".format(result[1]))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}