{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"\n", "Created on Wed Dec 18 09:15:05 2019"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["@author: Frank\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark import SparkContext\n", "from pyspark.streaming import StreamingContext\n", "from pyspark.sql import Row, SparkSession"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql.functions import regexp_extract"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a SparkSession (the config bit is only for Windows!)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark = SparkSession.builder.config(\"spark.sql.warehouse.dir\", \"file:///C:/temp\").appName(\"StructuredStreaming\").getOrCreate()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Monitor the logs directory for new log data, and read in the raw lines as accessLines"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["accessLines = spark.readStream.text(\"logs\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Parse out the common log format to a DataFrame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["contentSizeExp = r'\\s(\\d+)$'\n", "statusExp = r'\\s(\\d{3})\\s'\n", "generalExp = r'\\\"(\\S+)\\s(\\S+)\\s*(\\S*)\\\"'\n", "timeExp = r'\\[(\\d{2}/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2} -\\d{4})]'\n", "hostExp = r'(^\\S+\\.[\\S+\\.]+\\S+)\\s'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logsDF = accessLines.select(regexp_extract('value', hostExp, 1).alias('host'),\n", "                         regexp_extract('value', timeExp, 1).alias('timestamp'),\n", "                         regexp_extract('value', generalExp, 1).alias('method'),\n", "                         regexp_extract('value', generalExp, 2).alias('endpoint'),\n", "                         regexp_extract('value', generalExp, 3).alias('protocol'),\n", "                         regexp_extract('value', statusExp, 1).cast('integer').alias('status'),\n", "                         regexp_extract('value', contentSizeExp, 1).cast('integer').alias('content_size'))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Keep a running count of every access by status code"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["statusCountsDF = logsDF.groupBy(logsDF.status).count()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Kick off our streaming query, dumping results to the console"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query = ( statusCountsDF.writeStream.outputMode(\"complete\").format(\"console\").queryName(\"counts\").start() )"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Run forever until terminated"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query.awaitTermination()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Cleanly shut down the session"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark.stop()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}