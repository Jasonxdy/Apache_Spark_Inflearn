{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql import SparkSession\n", "from pyspark.sql.types import StructType, StructField, IntegerType, LongType\n", "from pyspark.ml.recommendation import ALS\n", "import sys\n", "import codecs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def loadMovieNames():\n", "    movieNames = {}\n", "    # CHANGE THIS TO THE PATH TO YOUR u.ITEM FILE:\n", "    with codecs.open(\"E:/SparkCourse/ml-100k/u.ITEM\", \"r\", encoding='ISO-8859-1', errors='ignore') as f:\n", "        for line in f:\n", "            fields = line.split('|')\n", "            movieNames[int(fields[0])] = fields[1]\n", "    return movieNames"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark = SparkSession.builder.appName(\"ALSExample\").getOrCreate()\n", "    \n", "moviesSchema = StructType([ \\\n", "                     StructField(\"userID\", IntegerType(), True), \\\n", "                     StructField(\"movieID\", IntegerType(), True), \\\n", "                     StructField(\"rating\", IntegerType(), True), \\\n", "                     StructField(\"timestamp\", LongType(), True)])\n", "    \n", "names = loadMovieNames()\n", "    \n", "ratings = spark.read.option(\"sep\", \"\\t\").schema(moviesSchema) \\\n", "    .csv(\"file:///SparkCourse/ml-100k/u.data\")\n", "    \n", "print(\"Training recommendation model...\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["als = ALS().setMaxIter(5).setRegParam(0.01).setUserCol(\"userID\").setItemCol(\"movieID\") \\\n", "    .setRatingCol(\"rating\")\n", "    \n", "model = als.fit(ratings)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Manually construct a dataframe of the user ID's we want recs for"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["userID = int(sys.argv[1])\n", "userSchema = StructType([StructField(\"userID\", IntegerType(), True)])\n", "users = spark.createDataFrame([[userID,]], userSchema)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["recommendations = model.recommendForUserSubset(users, 10).collect()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Top 10 recommendations for user ID \" + str(userID))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}