{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pyspark.sql import SparkSession"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pyspark.sql.functions as func"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create a SparkSession (the config bit is only for Windows!)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark = SparkSession.builder.appName(\"StructuredStreaming\").getOrCreate()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Monitor the logs directory for new log data, and read in the raw lines as accessLines"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["accessLines = spark.readStream.text(\"logs\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Parse out the common log format to a DataFrame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["contentSizeExp = r'\\s(\\d+)$'\n", "statusExp = r'\\s(\\d{3})\\s'\n", "generalExp = r'\\\"(\\S+)\\s(\\S+)\\s*(\\S*)\\\"'\n", "timeExp = r'\\[(\\d{2}/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2} -\\d{4})]'\n", "hostExp = r'(^\\S+\\.[\\S+\\.]+\\S+)\\s'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logsDF = accessLines.select(func.regexp_extract('value', hostExp, 1).alias('host'),\n", "                         func.regexp_extract('value', timeExp, 1).alias('timestamp'),\n", "                         func.regexp_extract('value', generalExp, 1).alias('method'),\n", "                         func.regexp_extract('value', generalExp, 2).alias('endpoint'),\n", "                         func.regexp_extract('value', generalExp, 3).alias('protocol'),\n", "                         func.regexp_extract('value', statusExp, 1).cast('integer').alias('status'),\n", "                         func.regexp_extract('value', contentSizeExp, 1).cast('integer').alias('content_size'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logsDF2 = logsDF.withColumn(\"eventTime\", func.current_timestamp())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Keep a running count of endpoints"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["endpointCounts = logsDF2.groupBy(func.window(func.col(\"eventTime\"), \\\n", "      \"30 seconds\", \"10 seconds\"), func.col(\"endpoint\")).count()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sortedEndpointCounts = endpointCounts.orderBy(func.col(\"count\").desc())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Display the stream to the console"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query = sortedEndpointCounts.writeStream.outputMode(\"complete\").format(\"console\") \\\n", "      .queryName(\"counts\").start()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Wait until we terminate the scripts"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query.awaitTermination()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Stop the session"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["spark.stop()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}