{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\n", "from pyspark import SparkConf, SparkContext\n", "from math import sqrt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def loadMovieNames():\n", "    movieNames = {}\n", "    with open(\"ml-100k/u.ITEM\", encoding='ascii', errors='ignore') as f:\n", "        for line in f:\n", "            fields = line.split('|')\n", "            movieNames[int(fields[0])] = fields[1]\n", "    return movieNames"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ython 3 doesn't let you pass around unpacked tuples,<br>\n", "o we explicitly extract the ratings now."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def makePairs( userRatings ):\n", "    ratings = userRatings[1]\n", "    (movie1, rating1) = ratings[0]\n", "    (movie2, rating2) = ratings[1]\n", "    return ((movie1, movie2), (rating1, rating2))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def filterDuplicates( userRatings ):\n", "    ratings = userRatings[1]\n", "    (movie1, rating1) = ratings[0]\n", "    (movie2, rating2) = ratings[1]\n", "    return movie1 < movie2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def computeCosineSimilarity(ratingPairs):\n", "    numPairs = 0\n", "    sum_xx = sum_yy = sum_xy = 0\n", "    for ratingX, ratingY in ratingPairs:\n", "        sum_xx += ratingX * ratingX\n", "        sum_yy += ratingY * ratingY\n", "        sum_xy += ratingX * ratingY\n", "        numPairs += 1\n", "    numerator = sum_xy\n", "    denominator = sqrt(sum_xx) * sqrt(sum_yy)\n", "    score = 0\n", "    if (denominator):\n", "        score = (numerator / (float(denominator)))\n", "    return (score, numPairs)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["conf = SparkConf().setMaster(\"local[*]\").setAppName(\"MovieSimilarities\")\n", "sc = SparkContext(conf = conf)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"\\nLoading movie names...\")\n", "nameDict = loadMovieNames()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = sc.textFile(\"file:///SparkCourse/ml-100k/u.data\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Map ratings to key / value pairs: user ID => movie ID, rating"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratings = data.map(lambda l: l.split()).map(lambda l: (int(l[0]), (int(l[1]), float(l[2]))))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Emit every movie rated together by the same user.<br>\n", "Self-join to find every combination."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["joinedRatings = ratings.join(ratings)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["At this point our RDD consists of userID => ((movieID, rating), (movieID, rating))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Filter out duplicate pairs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["uniqueJoinedRatings = joinedRatings.filter(filterDuplicates)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now key by (movie1, movie2) pairs."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["moviePairs = uniqueJoinedRatings.map(makePairs)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We now have (movie1, movie2) => (rating1, rating2)<br>\n", "Now collect all ratings for each movie pair and compute similarity"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["moviePairRatings = moviePairs.groupByKey()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We now have (movie1, movie2) = > (rating1, rating2), (rating1, rating2) ...<br>\n", "Can now compute similarities."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["moviePairSimilarities = moviePairRatings.mapValues(computeCosineSimilarity).cache()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Save the results if desired<br>\n", "oviePairSimilarities.sortByKey()<br>\n", "oviePairSimilarities.saveAsTextFile(\"movie-sims\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Extract similarities for the movie we care about that are \"good\"."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (len(sys.argv) > 1):\n", "    scoreThreshold = 0.97\n", "    coOccurenceThreshold = 50\n", "    movieID = int(sys.argv[1])\n\n", "    # Filter for movies with this sim that are \"good\" as defined by\n", "    # our quality thresholds above\n", "    filteredResults = moviePairSimilarities.filter(lambda pairSim: \\\n", "        (pairSim[0][0] == movieID or pairSim[0][1] == movieID) \\\n", "        and pairSim[1][0] > scoreThreshold and pairSim[1][1] > coOccurenceThreshold)\n\n", "    # Sort by quality score.\n", "    results = filteredResults.map(lambda pairSim: (pairSim[1], pairSim[0])).sortByKey(ascending = False).take(10)\n", "    print(\"Top 10 similar movies for \" + nameDict[movieID])\n", "    for result in results:\n", "        (sim, pair) = result\n", "        # Display the similarity result that isn't the movie we're looking at\n", "        similarMovieID = pair[0]\n", "        if (similarMovieID == movieID):\n", "            similarMovieID = pair[1]\n", "        print(nameDict[similarMovieID] + \"\\tscore: \" + str(sim[0]) + \"\\tstrength: \" + str(sim[1]))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}